\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Ablation Study}{69}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:ablation}{{5}{69}{Ablation Study}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Evaluation Methodology}{70}{section.5.1}\protected@file@percent }
\newlabel{sec:evaluation-methodology}{{5.1}{70}{Evaluation Methodology}{section.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Iterative Optimization Process}{70}{subsection.5.1.1}\protected@file@percent }
\newlabel{subsec:iterative-optimization-process}{{5.1.1}{70}{Iterative Optimization Process}{subsection.5.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Evaluation Metrics}{70}{subsection.5.1.2}\protected@file@percent }
\newlabel{subsec:ablation-metrics}{{5.1.2}{70}{Evaluation Metrics}{subsection.5.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Significance of the Methodology}{71}{subsection.5.1.3}\protected@file@percent }
\newlabel{subsec:significance-of-the-methodology}{{5.1.3}{71}{Significance of the Methodology}{subsection.5.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Document Selection}{71}{section.5.2}\protected@file@percent }
\newlabel{sec:document-selection}{{5.2}{71}{Document Selection}{section.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Unsupervised Methods}{72}{subsection.5.2.1}\protected@file@percent }
\newlabel{subsec:unsupervised-methods}{{5.2.1}{72}{Unsupervised Methods}{subsection.5.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{BM25:}{72}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Contriever:}{72}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Supervised Methods}{73}{subsection.5.2.2}\protected@file@percent }
\newlabel{subsec:supervised-methods}{{5.2.2}{73}{Supervised Methods}{subsection.5.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Jina.ai Reranker:}{73}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{MS MARCO MiniLM:}{74}{subsection.5.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Performance comparison of various distilled MS MARCO models based on BERT architecture, measured across NDCG@10 on TREC DL 2019 and MRR@10 on MS MARCO Dev benchmarks.}}{74}{table.caption.67}\protected@file@percent }
\newlabel{tab:ms-marco-model-comparison}{{5.1}{74}{Performance comparison of various distilled MS MARCO models based on BERT architecture, measured across NDCG@10 on TREC DL 2019 and MRR@10 on MS MARCO Dev benchmarks}{table.caption.67}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Evaluation with Large Language Models}{75}{subsection.5.2.3}\protected@file@percent }
\newlabel{subsec:evaluation-with-large-language-models}{{5.2.3}{75}{Evaluation with Large Language Models}{subsection.5.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Document retrieval confusion matrix based on Jaccard similarity between documents retrieved by each model.}}{75}{figure.caption.68}\protected@file@percent }
\newlabel{fig:document_retrieval_confusion_matrix}{{5.1}{75}{Document retrieval confusion matrix based on Jaccard similarity between documents retrieved by each model}{figure.caption.68}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Performance evaluation of various document retrieval methods on the FactBench dataset, using the Gemma2 model.}}{76}{table.caption.69}\protected@file@percent }
\newlabel{tab:evaluation_results}{{5.2}{76}{Performance evaluation of various document retrieval methods on the FactBench dataset, using the Gemma2 model}{table.caption.70}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Embedding Models}{77}{section.5.3}\protected@file@percent }
\newlabel{sec:embedding-models}{{5.3}{77}{Embedding Models}{section.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Gte-large-en-v1.5}{77}{subsection.5.3.1}\protected@file@percent }
\newlabel{subsec:alibaba-nlp}{{5.3.1}{77}{Gte-large-en-v1.5}{subsection.5.3.1}{}}
\AC@undonewlabel{acro:RoPE}
\newlabel{acro:RoPE}{{5.3.1}{77}{Gte-large-en-v1.5}{section*.71}{}}
\acronymused{RoPE}
\AC@undonewlabel{acro:MTEB}
\newlabel{acro:MTEB}{{5.3.1}{78}{Gte-large-en-v1.5}{section*.72}{}}
\acronymused{MTEB}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Jina-embeddings-v3}{78}{subsection.5.3.2}\protected@file@percent }
\newlabel{subsec:jinaai}{{5.3.2}{78}{Jina-embeddings-v3}{subsection.5.3.2}{}}
\acronymused{NLP}
\acronymused{RoPE}
\AC@undonewlabel{acro:LoRA}
\newlabel{acro:LoRA}{{5.3.2}{79}{Jina-embeddings-v3}{section*.73}{}}
\acronymused{LoRA}
\AC@undonewlabel{acro:MRL}
\newlabel{acro:MRL}{{5.3.2}{79}{Jina-embeddings-v3}{section*.74}{}}
\acronymused{MRL}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Stella\_en\_1.5B\_v5}{79}{subsection.5.3.3}\protected@file@percent }
\newlabel{subsec:dunzhang}{{5.3.3}{79}{Stella\_en\_1.5B\_v5}{subsection.5.3.3}{}}
\acronymused{MRL}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Multilingual-e5-large-instruct}{80}{subsection.5.3.4}\protected@file@percent }
\newlabel{subsec:nextcloud-ai}{{5.3.4}{80}{Multilingual-e5-large-instruct}{subsection.5.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}bge-small-en-v1.5}{81}{subsection.5.3.5}\protected@file@percent }
\newlabel{subsec:baai}{{5.3.5}{81}{bge-small-en-v1.5}{subsection.5.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Comparative Analysis}{81}{subsection.5.3.6}\protected@file@percent }
\newlabel{subsec:comparative-analysis}{{5.3.6}{81}{Comparative Analysis}{subsection.5.3.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Model Size and Efficiency:}{82}{subsection.5.3.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Comparison of characteristics of embedding models}}{82}{table.caption.75}\protected@file@percent }
\newlabel{tab:comparison-embeddings}{{5.3}{82}{Comparison of characteristics of embedding models}{table.caption.75}{}}
\@writefile{toc}{\contentsline {paragraph}{Language Coverage:}{82}{table.caption.75}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion:}{82}{table.caption.75}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Performance evaluation of various embedding models on the FactBench dataset, using the Gemma2 model.}}{83}{table.caption.76}\protected@file@percent }
\newlabel{tab:evaluation_results_embedding}{{5.4}{83}{Performance evaluation of various embedding models on the FactBench dataset, using the Gemma2 model}{table.caption.77}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Chunking Strategies}{84}{section.5.4}\protected@file@percent }
\newlabel{sec:chunking-strategies}{{5.4}{84}{Chunking Strategies}{section.5.4}{}}
\acronymused{RAG}
\acronymused{RAG}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Parsing Documents into Text Chunks}{84}{subsection.5.4.1}\protected@file@percent }
\newlabel{subsec:parsing-documents-into-text-chunks}{{5.4.1}{84}{Parsing Documents into Text Chunks}{subsection.5.4.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Methodology:}{84}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Chunk Sizes:}{84}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Smaller Child Chunks Referring to Bigger Parent Chunks (Small2Big)}{84}{subsection.5.4.2}\protected@file@percent }
\newlabel{subsec:smaller-child-chunks-referring-to-bigger-parent-chunks}{{5.4.2}{84}{Smaller Child Chunks Referring to Bigger Parent Chunks (Small2Big)}{subsection.5.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Methodology:}{85}{subsection.5.4.2}\protected@file@percent }
\newlabel{lst:small2big_chunking}{{5.1}{85}{Small2Big chunking method}{lstlisting.5.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.1}{\ignorespaces Small2Big chunking method}}{85}{lstlisting.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Sentence Window Retrieval}{85}{subsection.5.4.3}\protected@file@percent }
\newlabel{subsec:sentence-window-retrieval}{{5.4.3}{85}{Sentence Window Retrieval}{subsection.5.4.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Methodology:}{86}{subsection.5.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Node sentence window replacement technique as described by Liu~\blx@tocontentsinit {0}\cite {liu2023tweet}.}}{86}{figure.caption.78}\protected@file@percent }
\newlabel{fig:window-ret}{{5.2}{86}{Node sentence window replacement technique as described by Liu~\cite {liu2023tweet}}{figure.caption.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Advantages and Limitations}{86}{subsection.5.4.4}\protected@file@percent }
\newlabel{subsec:advantages-and-limitations}{{5.4.4}{86}{Advantages and Limitations}{subsection.5.4.4}{}}
\gdef \LT@iii {\LT@entry 
    {1}{91.59993pt}\LT@entry 
    {1}{163.32687pt}\LT@entry 
    {1}{163.32687pt}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Advantages and Limitations of different chunking strategies for RAG systems.}}{87}{table.caption.79}\protected@file@percent }
\newlabel{tab:window-segmentation-analysis}{{5.5}{87}{Advantages and Limitations of different chunking strategies for RAG systems}{table.caption.79}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.5}Evaluation}{87}{subsection.5.4.5}\protected@file@percent }
\newlabel{subsec:evaluation}{{5.4.5}{87}{Evaluation}{subsection.5.4.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces Performance evaluation of various chunking strategy on the FactBench dataset, using the Gemma2 model.}}{88}{table.caption.80}\protected@file@percent }
\newlabel{tab:table_chunking}{{5.6}{88}{Performance evaluation of various chunking strategy on the FactBench dataset, using the Gemma2 model}{table.caption.80}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Similarity Cut-off}{88}{section.5.5}\protected@file@percent }
\newlabel{sec:similar-cut-off}{{5.5}{88}{Similarity Cut-off}{section.5.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Similarity Cutoff Postprocessor (re-rank score)}}{88}{algorithm.3}\protected@file@percent }
\newlabel{alg:algorithm}{{3}{88}{Similarity Cutoff Postprocessor (re-rank score)}{algorithm.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces Performance evaluation of similarity cut-off method on the FactBench dataset, using the Gemma2 model.}}{89}{table.caption.81}\protected@file@percent }
\newlabel{tab:table_similarity_cut}{{5.7}{89}{Performance evaluation of similarity cut-off method on the FactBench dataset, using the Gemma2 model}{table.caption.82}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Top K}{89}{section.5.6}\protected@file@percent }
\newlabel{sec:top-k}{{5.6}{89}{Top K}{section.5.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.8}{\ignorespaces Performance evaluation of different Top\_k retrieval strategies on the FactBench dataset using the Gemma2 model. }}{89}{table.caption.83}\protected@file@percent }
\newlabel{tab:table_top_k}{{5.8}{89}{Performance evaluation of different Top\_k retrieval strategies on the FactBench dataset using the Gemma2 model}{table.caption.84}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Evaluation}{90}{section.5.7}\protected@file@percent }
\newlabel{sec:evaluation-and-discussion}{{5.7}{90}{Evaluation}{section.5.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Category-wise performance of different models in identifying Positive Labels (left) and Negative Labels (right) on the FactBench dataset.}}{90}{figure.caption.85}\protected@file@percent }
\newlabel{fig:radar-charts}{{5.3}{90}{Category-wise performance of different models in identifying Positive Labels (left) and Negative Labels (right) on the FactBench dataset}{figure.caption.85}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.9}{\ignorespaces Category-wise performance evaluation results of various models on the FactBench dataset.}}{91}{table.caption.86}\protected@file@percent }
\newlabel{tab:evaluation_results-full-category}{{5.9}{91}{Category-wise performance evaluation results of various models on the FactBench dataset}{table.caption.86}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.10}{\ignorespaces Performance evaluation of various models on the FactBench dataset.}}{91}{table.caption.87}\protected@file@percent }
\newlabel{tab:evaluation_results-full-wo-category}{{5.10}{91}{Performance evaluation of various models on the FactBench dataset}{table.caption.88}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Failure Analysis}{91}{section.5.8}\protected@file@percent }
\newlabel{sec:faiure-analysis}{{5.8}{91}{Failure Analysis}{section.5.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Error Type Categorization:}{91}{section.5.8}\protected@file@percent }
\gdef \LT@iv {\LT@entry 
    {1}{97.35826pt}\LT@entry 
    {1}{97.35826pt}\LT@entry 
    {1}{223.53716pt}}
\@writefile{lot}{\contentsline {table}{\numberline {5.11}{\ignorespaces Example of failure cases and error analysis observed in the FactBench dataset using generated results and explanations.}}{92}{table.caption.89}\protected@file@percent }
\newlabel{tab:factbench-failure-analysis}{{5.11}{92}{Example of failure cases and error analysis observed in the FactBench dataset using generated results and explanations}{table.caption.89}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Prediction accuracy on the FactBench dataset, focusing on incorrect predictions. The right chart illustrates the Distribution of Fully Incorrect Predictions (4/4), detailing the instances where all predictions made by the models were incorrect. The left chart depicts the Distribution of Partially Incorrect Predictions (3/4).}}{93}{figure.caption.90}\protected@file@percent }
\newlabel{fig:wrong_prediction_distribution}{{5.4}{93}{Prediction accuracy on the FactBench dataset, focusing on incorrect predictions. The right chart illustrates the Distribution of Fully Incorrect Predictions (4/4), detailing the instances where all predictions made by the models were incorrect. The left chart depicts the Distribution of Partially Incorrect Predictions (3/4)}{figure.caption.90}{}}
\@setckpt{chapters/05_ablation}{
\setcounter{page}{94}
\setcounter{equation}{3}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{7}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{8}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{11}
\setcounter{section@level}{0}
\setcounter{Item}{13}
\setcounter{Hfootnote}{25}
\setcounter{bookmark@seq@number}{93}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{16}
\setcounter{algorithm}{3}
\setcounter{ALG@line}{12}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{lstnumber}{18}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{80}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{3}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{FancyVerbLine}{0}
\setcounter{r@tfl@t}{0}
\setcounter{LT@tables}{4}
\setcounter{LT@chunks}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{lstlisting}{1}
}
