\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Distinctions between human and LLM Inferences. The entailment prediction performance of humans and LLMs are depicted by a 5-star rating scale~\blx@tocontentsinit {0}\cite {sanyal2024machinesbettercomplexreasoning}.}}{8}{figure.caption.21}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Comparison of claim verification systems between NLP-based (traditional) and LLM-based for claim veracity.~\blx@tocontentsinit {0}\cite {dmonte2024claimverificationagelarge}.}}{10}{figure.caption.22}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces The proposed RAFTS~\blx@tocontentsinit {0}\cite {yue2024retrievalaugmentedfactverification}, which performs few-shot fact verification by incorporating informative in-context demonstrations and contrastive arguments with nuanced information derived from the retrieved documents}}{12}{figure.caption.23}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces An overview of the fact-checking pipeline contrasting the baseline Sub-Question Generation approach from the Chain of RAG and Tree of RAG approach followed by veracity prediction and explanation.}}{13}{figure.caption.24}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces RAG-Based Fact Verification Pipeline}}{16}{figure.caption.25}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Cross-Encoder component, which assesses the relevance of generated questions by taking multiple input pairs and assigning a relevance score to each, supporting question evaluation and refinement.}}{20}{figure.caption.27}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Knowledge Distillation Process for Enhanced Re-Ranking Efficiency}}{21}{figure.caption.28}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Fetching results from Google Search engine for top $N$ questions and the main knowledge graph query.}}{23}{figure.caption.30}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Extracted content from the crawled URLs using newspaper4k library.}}{25}{figure.caption.32}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Document Retrieval Confusion Matrix based on Jaccard Similarity between documents retrieved by each model.}}{59}{figure.caption.48}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Node sentence window replacement technique as described by Liu~\blx@tocontentsinit {0}\cite {liu2023tweet}.}}{70}{figure.caption.58}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Category-wise performance of different models in identifying Positive Labels (left) and Negative Labels (right) on the FactBench dataset.}}{74}{figure.caption.65}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Prediction accuracy on the FactBench dataset, focusing on incorrect predictions. The left chart illustrates the Distribution of Fully Incorrect Predictions (4/4), detailing the instances where all predictions made by the model were incorrect. The right chart depicts the Distribution of Partially Incorrect Predictions (3/4).}}{77}{figure.caption.69}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
